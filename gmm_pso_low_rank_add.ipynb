{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cloud data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.mixture._gaussian_mixture import _compute_precision_cholesky\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Cloud dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_data_name = 'data/cloud.data'\n",
    "with open(cloud_data_name) as f:\n",
    "    cloud_data = pd.DataFrame([item.split() for item in f.readlines()])\n",
    "cloud_data = cloud_data.astype(float).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(cloud_data)\n",
    "cloud_data = scaler.transform(cloud_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_data_name = 'data/wdbc.data'\n",
    "with open(bc_data_name) as f:\n",
    "    data_bc = pd.DataFrame([item.split(',')[2:] for item in f.readlines()])\n",
    "data_bc = data_bc.astype(float).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data_bc)\n",
    "data_bc = scaler.transform(data_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading LandSat Satelite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_trn_data_name = 'data/sat.trn'\n",
    "\n",
    "with open(sat_trn_data_name) as f:\n",
    "    data_sat_trn = pd.DataFrame([item.split(' ')[:36] for item in f.readlines()])\n",
    "data_sat_trn = data_sat_trn.astype(float).to_numpy()\n",
    "\n",
    "sat_tst_data_name = 'data/sat.tst'\n",
    "with open(sat_tst_data_name) as f:\n",
    "    data_sat_tst = pd.DataFrame([item.split(' ')[:36] for item in f.readlines()])\n",
    "data_sat_tst = data_sat_tst.astype(float).to_numpy()\n",
    "\n",
    "data_sat = np.concatenate([data_sat_trn, data_sat_tst], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data_sat)\n",
    "data_sat = scaler.transform(data_sat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(20, 20), dpi=80)\n",
    "plt.rcParams[\"figure.figsize\"] = (20,20)\n",
    "\n",
    "def plot_particle_trajectories(trajectories, best_em):\n",
    "    for i in range(len(trajectories)):\n",
    "        plt.plot(list(range(len(trajectories[i]))), trajectories[i])\n",
    "    plt.plot(list(range(len(trajectories[i]))), [best_em for i in range(len(trajectories[i]))], linewidth=3, c='black')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinit_gaussian(data, basic_means, basic_prec, n_components, rank, weights, delta_means, delta_diag, delta_rank_params):\n",
    "    means = basic_means + delta_means\n",
    "\n",
    "    prec_matr = basic_prec\n",
    "\n",
    "    cholesky = np.zeros_like(prec_matr)\n",
    "    \n",
    "    for i in range(n_components):\n",
    "\n",
    "        prec_matr[i] += np.diag(delta_diag[i] ** 2)\n",
    "\n",
    "        for k in range(rank):\n",
    "            prec_matr[i] += delta_rank_params[i][k] @ delta_rank_params[i][k].T\n",
    "\n",
    "        cholesky[i] = np.linalg.cholesky(prec_matr[i])\n",
    "\n",
    "    gmm_init = GaussianMixture(n_components=weights.shape[0], covariance_type='full', weights_init=weights, means_init=means, precisions_init=prec_matr)\n",
    "    gmm_init.fit(data)\n",
    "    return gmm_init.score(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSO with low rank PD addition method for GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_delta_parametrize(data, log_file_name, n_components=10, amplitude=0.05, rank=10, init_scale=1):\n",
    "    # write PSO and k means algo\n",
    "    n_particles = 50\n",
    "    max_i = 40\n",
    "    w = 0.5\n",
    "    r_1 = 0.6\n",
    "    r_2 = 0.8\n",
    "    r_1_chol = 0.42\n",
    "    r_2_chol = 0.57\n",
    "    r_1_w = 0.42\n",
    "    r_2_w = 0.57\n",
    "    data_dim = data.shape[1]\n",
    "\n",
    "    if rank > data_dim:\n",
    "        rank = data_dim\n",
    "\n",
    "    particle_trajectories = [[] for i in range(n_particles)]\n",
    "    \n",
    "    criterions = [0 for i in range(n_particles)]\n",
    "    from functools import partial\n",
    "    \n",
    "    with open(log_file_name, 'w+') as f:\n",
    "        \n",
    "            \n",
    "        v_weights = np.random.uniform(-1, 1, size=(n_particles, n_components))\n",
    "        v_delta_means = np.random.uniform(-1, 1, size=(n_particles, n_components, data_dim))\n",
    "        v_delta_diag_prec = np.random.uniform(-1, 1, size=(n_particles, n_components, data_dim))\n",
    "        v_delta_param_prec = np.random.uniform(-1, 1, size=(n_particles, n_components, rank, data_dim))\n",
    "\n",
    "        delta_means = np.zeros((n_particles, n_components, data_dim))\n",
    "        weights = np.zeros((n_particles, n_components))\n",
    "        delta_diag_prec = np.zeros((n_particles, n_components, data_dim))\n",
    "        delta_param_prec = np.zeros((n_particles, n_components, rank, data_dim))\n",
    "\n",
    "        # one BIG GMM init\n",
    "\n",
    "        gmm = GaussianMixture(n_components=n_components, covariance_type='full', init_params='random', n_init=100)\n",
    "        gmm.fit(data)\n",
    "        basic_score = gmm.score(data)\n",
    "        f.write(f'EM init {basic_score}')\n",
    "\n",
    "        base_chol = gmm.precisions_cholesky_\n",
    "\n",
    "        basic_prec = np.zeros_like(gmm.precisions_cholesky_)\n",
    "        for i in range(gmm.precisions_cholesky_.shape[0]):\n",
    "            basic_prec[i] = gmm.precisions_cholesky_[i] @ gmm.precisions_cholesky_[i].T\n",
    "\n",
    "        FB_base_chol = np.zeros_like(gmm.precisions_cholesky_)\n",
    "        for i in range(gmm.precisions_cholesky_.shape[0]):\n",
    "            FB_base_chol[i] = np.linalg.cholesky(basic_prec[i])\n",
    "\n",
    "\n",
    "        basic_means = gmm.means_\n",
    "\n",
    "        g_best_reinit = 0\n",
    "\n",
    "        def is_pos_def(x):\n",
    "            return np.all(np.linalg.eigvals(x) > 0)\n",
    "\n",
    "        def log_likelihood_gmm_parametrized(weights, delta_means, delta_diag, delta_rank_params):\n",
    "            means = basic_means + delta_means\n",
    "\n",
    "            prec_matr = basic_prec\n",
    "\n",
    "            cholesky = np.zeros_like(prec_matr)\n",
    "            \n",
    "            for i in range(n_components):\n",
    "\n",
    "                prec_matr[i] += np.diag(delta_diag[i] ** 2)\n",
    "\n",
    "                for k in range(rank):\n",
    "                    prec_matr[i] += delta_rank_params[i][k] @ delta_rank_params[i][k].T\n",
    "\n",
    "                cholesky[i] = np.linalg.cholesky(prec_matr[i])\n",
    "\n",
    "            gmm_init = GaussianMixture(n_components=weights.shape[0], covariance_type='full', weights_init=weights, means_init=means)\n",
    "            gmm_init.weights_ = weights\n",
    "            gmm_init.means_ = means\n",
    "            gmm_init.precisions_cholesky_ = cholesky\n",
    "            return gmm_init.score(data)\n",
    "\n",
    "        def reinit_gaussian(weights, delta_means, delta_diag, delta_rank_params):\n",
    "            means = basic_means + delta_means\n",
    "\n",
    "            prec_matr = basic_prec\n",
    "\n",
    "            cholesky = np.zeros_like(prec_matr)\n",
    "            \n",
    "            for i in range(n_components):\n",
    "\n",
    "                prec_matr[i] += np.diag(delta_diag[i] ** 2)\n",
    "\n",
    "                for k in range(rank):\n",
    "                    prec_matr[i] += delta_rank_params[i][k] @ delta_rank_params[i][k].T\n",
    "\n",
    "                cholesky[i] = np.linalg.cholesky(prec_matr[i])\n",
    "\n",
    "            gmm_init = GaussianMixture(n_components=weights.shape[0], covariance_type='full', weights_init=weights, means_init=means, precisions_init=prec_matr)\n",
    "            gmm_init.fit(data)\n",
    "            return gmm_init.score(data)\n",
    "\n",
    "        # randomly init delta\n",
    "        for i in range(n_particles):\n",
    "            delta_means[i] = np.random.normal(0, init_scale, size=gmm.means_.shape)\n",
    "            weights[i] = gmm.weights_\n",
    "            delta_diag_prec[i] = np.random.normal(0, init_scale, size=delta_diag_prec[i].shape)\n",
    "            delta_param_prec[i] = np.random.normal(0, init_scale, size=delta_param_prec[i].shape)\n",
    "\n",
    "        p_weights = np.copy(weights)\n",
    "        p_delta_means = np.copy(delta_means)\n",
    "        p_delta_diag_prec = np.copy(delta_diag_prec)\n",
    "        p_delta_param_prec = np.copy(delta_param_prec)\n",
    "\n",
    "        g_weights = np.copy(weights[0])\n",
    "        g_delta_means = np.copy(delta_means[0])\n",
    "        g_delta_diag_prec = np.copy(delta_diag_prec[0])\n",
    "        g_delta_param_prec = np.copy(delta_param_prec[0])\n",
    "\n",
    "        for i in range(n_particles):\n",
    "            if log_likelihood_gmm_parametrized(p_weights[i], p_delta_means[i], p_delta_diag_prec[i], p_delta_param_prec[i]) > log_likelihood_gmm_parametrized(g_weights, g_delta_means, g_delta_diag_prec, g_delta_param_prec):\n",
    "                g_weights = np.copy(p_weights[i])\n",
    "                g_delta_means = np.copy(p_delta_means[i])\n",
    "                g_delta_diag_prec = np.copy(p_delta_diag_prec[i])\n",
    "                g_delta_param_prec = np.copy(p_delta_param_prec[i])\n",
    "        \n",
    "        f.write(f'Best initial log likelihood {log_likelihood_gmm_parametrized(g_weights, g_delta_means, g_delta_diag_prec, g_delta_param_prec)}\\n')\n",
    "        # Data for the plotting\n",
    "        best_loglikelihood_init = log_likelihood_gmm_parametrized(g_weights, g_delta_means, g_delta_diag_prec, g_delta_param_prec)\n",
    "        pso_best_loglikelihood = []\n",
    "\n",
    "        iter_n = -1\n",
    "        while (iter_n < max_i):\n",
    "\n",
    "            f.write(f'Iter {iter_n}\\n')\n",
    "\n",
    "            # reinit GMM here\n",
    "            # in case it is not the first iteration\n",
    "\n",
    "            gmm_reinit_list = []\n",
    "\n",
    "            # update personal best\n",
    "            for i in range(n_particles):\n",
    "                criterions[i] = log_likelihood_gmm_parametrized(weights[i], delta_means[i], delta_diag_prec[i], delta_param_prec[i])\n",
    "                particle_trajectories[i].append(criterions[i])\n",
    "                if log_likelihood_gmm_parametrized(p_weights[i], p_delta_means[i], p_delta_diag_prec[i], p_delta_param_prec[i]) < criterions[i]:\n",
    "                    p_weights[i] = np.copy(weights[i])\n",
    "                    p_delta_means[i] = np.copy(delta_means[i])\n",
    "                    p_delta_diag_prec[i] = np.copy(delta_diag_prec[i])\n",
    "                    p_delta_param_prec[i] = np.copy(p_delta_param_prec[i])\n",
    "        \n",
    "            g_new_weights = np.copy(g_weights)\n",
    "            g_new_delta_means = np.copy(g_delta_means)\n",
    "            g_new_delta_diag_prec = np.copy(g_delta_diag_prec)\n",
    "            g_new_delta_param_prec = np.copy(g_delta_param_prec)\n",
    "\n",
    "            # updating global best\n",
    "            for i in range(n_particles):\n",
    "                if log_likelihood_gmm_parametrized(p_weights[i], p_delta_means[i], p_delta_diag_prec[i], p_delta_param_prec[i]) > log_likelihood_gmm_parametrized(g_new_weights, g_new_delta_means, g_new_delta_diag_prec, g_new_delta_param_prec):\n",
    "                    g_new_weights = np.copy(p_weights[i])\n",
    "                    g_new_delta_means = np.copy(p_delta_means[i])\n",
    "                    g_new_delta_diag_prec = np.copy(p_delta_diag_prec[i])\n",
    "                    g_new_delta_param_prec = np.copy(p_delta_param_prec[i])\n",
    "                \n",
    "\n",
    "            # if there are no imprevements\n",
    "            delta_global = log_likelihood_gmm_parametrized(g_new_weights, g_new_delta_means, g_new_delta_diag_prec, g_new_delta_param_prec) - log_likelihood_gmm_parametrized(g_weights, g_delta_means, g_delta_diag_prec, g_delta_param_prec)\n",
    "            \n",
    "            if delta_global > 0:\n",
    "                g_weights = np.copy(g_new_weights)\n",
    "                g_delta_means = np.copy(g_new_delta_means)\n",
    "                g_delta_diag_prec = np.copy(g_new_delta_diag_prec)\n",
    "                g_delta_param_prec = np.copy(g_new_delta_param_prec)\n",
    "\n",
    "            iter_n += 1\n",
    "            \n",
    "            # PSO update\n",
    "            for j in range(n_particles):\n",
    "                c_1 = np.random.uniform(0, 1)\n",
    "                c_2 = np.random.uniform(0, 1)\n",
    "\n",
    "                # weights\n",
    "                # deleted v_weights * w to exclude probability that weights will go below zero\n",
    "                v_weights[j] = c_1 * r_1_w * (p_weights[j] - weights[j]) + c_2 * r_2_w * (g_weights - weights[j])\n",
    "                weights[j] += amplitude * v_weights[j]\n",
    "\n",
    "                v_delta_means[j] = c_1 * r_1 * (p_delta_means[j] - delta_means[j]) + c_2 * r_2 * (g_delta_means - delta_means[j])\n",
    "                delta_means[j] += amplitude * v_delta_means[j]\n",
    "\n",
    "                v_delta_diag_prec[j] = c_1 * r_1 * (p_delta_diag_prec[j] - delta_diag_prec[j]) + c_2 * r_2 * (g_delta_diag_prec - delta_diag_prec[j])\n",
    "                delta_diag_prec[j] += amplitude * v_delta_diag_prec[j]\n",
    "\n",
    "                v_delta_param_prec[j] = c_1 * r_1 * (p_delta_param_prec[j] - delta_param_prec[j]) + c_2 * r_2 * (g_delta_param_prec - delta_param_prec[j])\n",
    "                delta_param_prec[j] +=  amplitude * v_delta_param_prec[j]\n",
    "                \n",
    "            f.write(f'Best log likelihood {log_likelihood_gmm_parametrized(g_weights, g_delta_means, g_delta_diag_prec, g_delta_param_prec)}\\n')\n",
    "            pso_best_loglikelihood.append(log_likelihood_gmm_parametrized(g_weights, g_delta_means, g_delta_diag_prec, g_delta_param_prec))\n",
    "            f.write(f'Reinit gaussians\\n')\n",
    "\n",
    "            if iter_n % 10 == 0:\n",
    "                best_reinit = 0\n",
    "                for i in range(n_particles):\n",
    "                    score = reinit_gaussian(p_weights[i], p_delta_means[i], p_delta_diag_prec[i], p_delta_param_prec[i])\n",
    "                    if score > best_reinit:\n",
    "                        best_reinit = score\n",
    "\n",
    "                f.write(str(best_reinit) + '\\n')\n",
    "\n",
    "                if g_best_reinit < best_reinit:\n",
    "                    g_best_reinit = best_reinit\n",
    "\n",
    "            f.flush()\n",
    "\n",
    "        # gmm_large = GaussianMixture(n_components=10, covariance_type='full', init_params='random', n_init=300)\n",
    "        # gmm_large.fit(data)\n",
    "        # f.write(f'GMM large with 300 init Score {gmm.score(cloud_data)}')\n",
    "\n",
    "\n",
    "        large_gmm_init_score = 0\n",
    "    return pso_best_loglikelihood, best_loglikelihood_init, large_gmm_init_score, particle_trajectories, g_best_reinit, basic_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\pso\\PSO_GMM\\gmm_pso_low_rank_add.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X22sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_runs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X22sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     log_file_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpso_low_rank_parametrize_init_scale_\u001b[39m\u001b[39m{\u001b[39;00minit_scale\u001b[39m}\u001b[39;00m\u001b[39m_n_comp_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m10\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m_ampl_\u001b[39m\u001b[39m{\u001b[39;00mampl\u001b[39m}\u001b[39;00m\u001b[39m_rank_\u001b[39m\u001b[39m{\u001b[39;00mrank\u001b[39m}\u001b[39;00m\u001b[39m.log\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X22sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     pso_best_loglikelihood, best_loglikelihood_init, large_gmm_init_score, particle_trajectories, g_best_reinit, basic_score \u001b[39m=\u001b[39m run_experiment_delta_parametrize(cloud_data, log_file_name, n_components\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, amplitude\u001b[39m=\u001b[39;49mampl, rank\u001b[39m=\u001b[39;49mrank, init_scale\u001b[39m=\u001b[39;49minit_scale)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X22sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     g_best_reinit_list\u001b[39m.\u001b[39mappend(g_best_reinit)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X22sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     basic_score_list\u001b[39m.\u001b[39mappend(basic_score)\n",
      "\u001b[1;32md:\\Projects\\pso\\PSO_GMM\\gmm_pso_low_rank_add.ipynb Cell 17\u001b[0m in \u001b[0;36mrun_experiment_delta_parametrize\u001b[1;34m(data, log_file_name, n_components, amplitude, rank, init_scale)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X22sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# one BIG GMM init\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X22sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m gmm \u001b[39m=\u001b[39m GaussianMixture(n_components\u001b[39m=\u001b[39mn_components, covariance_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m'\u001b[39m, init_params\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrandom\u001b[39m\u001b[39m'\u001b[39m, n_init\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X22sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m gmm\u001b[39m.\u001b[39;49mfit(data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X22sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m basic_score \u001b[39m=\u001b[39m gmm\u001b[39m.\u001b[39mscore(data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X22sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m f\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEM init \u001b[39m\u001b[39m{\u001b[39;00mbasic_score\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kholk\\Envs\\ml_base\\lib\\site-packages\\sklearn\\mixture\\_base.py:200\u001b[0m, in \u001b[0;36mBaseMixture.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    175\u001b[0m     \u001b[39m\"\"\"Estimate model parameters with the EM algorithm.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \n\u001b[0;32m    177\u001b[0m \u001b[39m    The method fits the model ``n_init`` times and sets the parameters with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39m        The fitted mixture.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_predict(X, y)\n\u001b[0;32m    201\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\kholk\\Envs\\ml_base\\lib\\site-packages\\sklearn\\mixture\\_base.py:264\u001b[0m, in \u001b[0;36mBaseMixture.fit_predict\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[39mfor\u001b[39;00m n_iter \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_iter \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m    262\u001b[0m     prev_lower_bound \u001b[39m=\u001b[39m lower_bound\n\u001b[1;32m--> 264\u001b[0m     log_prob_norm, log_resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_e_step(X)\n\u001b[0;32m    265\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_m_step(X, log_resp)\n\u001b[0;32m    266\u001b[0m     lower_bound \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_lower_bound(log_resp, log_prob_norm)\n",
      "File \u001b[1;32mc:\\Users\\kholk\\Envs\\ml_base\\lib\\site-packages\\sklearn\\mixture\\_base.py:321\u001b[0m, in \u001b[0;36mBaseMixture._e_step\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_e_step\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    306\u001b[0m     \u001b[39m\"\"\"E step.\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \n\u001b[0;32m    308\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[39m        the point of each sample in X.\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 321\u001b[0m     log_prob_norm, log_resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_estimate_log_prob_resp(X)\n\u001b[0;32m    322\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(log_prob_norm), log_resp\n",
      "File \u001b[1;32mc:\\Users\\kholk\\Envs\\ml_base\\lib\\site-packages\\sklearn\\mixture\\_base.py:541\u001b[0m, in \u001b[0;36mBaseMixture._estimate_log_prob_resp\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_estimate_log_prob_resp\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    523\u001b[0m     \u001b[39m\"\"\"Estimate log probabilities and responsibilities for each sample.\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \n\u001b[0;32m    525\u001b[0m \u001b[39m    Compute the log probabilities, weighted log probabilities per\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[39m        logarithm of the responsibilities\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 541\u001b[0m     weighted_log_prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_estimate_weighted_log_prob(X)\n\u001b[0;32m    542\u001b[0m     log_prob_norm \u001b[39m=\u001b[39m logsumexp(weighted_log_prob, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    543\u001b[0m     \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(under\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    544\u001b[0m         \u001b[39m# ignore underflow\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kholk\\Envs\\ml_base\\lib\\site-packages\\sklearn\\mixture\\_base.py:494\u001b[0m, in \u001b[0;36mBaseMixture._estimate_weighted_log_prob\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_estimate_weighted_log_prob\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    484\u001b[0m     \u001b[39m\"\"\"Estimate the weighted log-probabilities, log P(X | Z) + log weights.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[0;32m    486\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[39m    weighted_log_prob : array, shape (n_samples, n_component)\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 494\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_estimate_log_prob(X) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_estimate_log_weights()\n",
      "File \u001b[1;32mc:\\Users\\kholk\\Envs\\ml_base\\lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py:760\u001b[0m, in \u001b[0;36mGaussianMixture._estimate_log_prob\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    759\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_estimate_log_prob\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m--> 760\u001b[0m     \u001b[39mreturn\u001b[39;00m _estimate_log_gaussian_prob(\n\u001b[0;32m    761\u001b[0m         X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmeans_, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecisions_cholesky_, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcovariance_type\n\u001b[0;32m    762\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kholk\\Envs\\ml_base\\lib\\site-packages\\sklearn\\mixture\\_gaussian_mixture.py:427\u001b[0m, in \u001b[0;36m_estimate_log_gaussian_prob\u001b[1;34m(X, means, precisions_chol, covariance_type)\u001b[0m\n\u001b[0;32m    425\u001b[0m     log_prob \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty((n_samples, n_components))\n\u001b[0;32m    426\u001b[0m     \u001b[39mfor\u001b[39;00m k, (mu, prec_chol) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(means, precisions_chol)):\n\u001b[1;32m--> 427\u001b[0m         y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(X, prec_chol) \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mdot(mu, prec_chol)\n\u001b[0;32m    428\u001b[0m         log_prob[:, k] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39msquare(y), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    430\u001b[0m \u001b[39melif\u001b[39;00m covariance_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtied\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "init_scale_range = [0.01, 0.0005]\n",
    "n_comp = [10]\n",
    "ampl_list = [0.1]\n",
    "\n",
    "# recipe for experiments: EM inti iter =100, high ampl (lr), 100 pso iters, compare with EM init 200 iter\n",
    "# note: low lr for big number of components, try rank = 3, 5, 7\n",
    "# Add best EM init with zero addition\n",
    "# add an csv logging\n",
    "# fix a bug with global best\n",
    "rank = 5\n",
    "n_runs = 5\n",
    "init_scale = 0.01\n",
    "init_scale = 0.05\n",
    "\n",
    "ampl = 0.1\n",
    "\n",
    "g_best_reinit_list = []\n",
    "basic_score_list = []\n",
    "for n in range(n_runs):\n",
    "    log_file_name = f'pso_low_rank_parametrize_init_scale_{init_scale}_n_comp_{10}_ampl_{ampl}_rank_{rank}.log'\n",
    "    pso_best_loglikelihood, best_loglikelihood_init, large_gmm_init_score, particle_trajectories, g_best_reinit, basic_score = run_experiment_delta_parametrize(cloud_data, log_file_name, n_components=10, amplitude=ampl, rank=rank, init_scale=init_scale)\n",
    "    g_best_reinit_list.append(g_best_reinit)\n",
    "    basic_score_list.append(basic_score)\n",
    "    final_score = pso_best_loglikelihood[-1]\n",
    "\n",
    "print('Best scattered reinit', np.mean(g_best_reinit_list), '+-' , np.std(g_best_reinit_list))\n",
    "print('Best EM init', np.mean(basic_score_list), '+-' , np.std(basic_score_list))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting on Breast Cancer dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N init 100 74.22707489636325 0.2958389267731283\n"
     ]
    }
   ],
   "source": [
    "n_components_list = [3, 5, 8, 10, 15, 20, 25]\n",
    "scores = []\n",
    "n_runs = 10\n",
    "\n",
    "# for n in range(n_runs):\n",
    "#     gmm_bc = GaussianMixture(n_components=10, covariance_type='full', n_init=300)\n",
    "#     gmm_bc = gmm_bc.fit(data_bc)\n",
    "#     scores.append(gmm_bc.score(data_bc))\n",
    "\n",
    "# print('N init 300', np.mean(scores), np.std(scores))\n",
    "\n",
    "for n in range(n_runs):\n",
    "    gmm_bc = GaussianMixture(n_components=10, init_params='random', covariance_type='full', n_init=100)\n",
    "    gmm_bc = gmm_bc.fit(data_bc)\n",
    "    scores.append(gmm_bc.score(data_bc))\n",
    "\n",
    "print('N init 100', np.mean(scores), np.std(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.2621077979399"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_bc = GaussianMixture(n_components=10, init_params='random', covariance_type='full', n_init=100)\n",
    "gmm_bc = gmm_bc.fit(data_bc)\n",
    "gmm_bc.score(data_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'breast_cancer_pso_low_rank_parametrize_init_scale_0.003_n_comp_15_ampl_0.003_rank_10.log'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64.59361355960428, 63.73920897296934, 63.0188242672728, 62.2902393427207, 61.59456434148814, 60.882113100840755, 60.16980699498362, 59.46469414992337, 58.76727139485888, 58.08163654322721, 57.40144917268593, 56.57068921302553, 55.908538430150415, 55.24679123428107, 54.58572761986928, 53.92738272646766, 53.27225292853626, 52.618002969535574, 51.96794963491328, 51.32392224132101, 50.68101983346345, 49.88008943197019, 49.241856916275935, 48.60718463472704, 47.975816275437914, 47.34616715244728, 46.713423979015516, 46.11468913290573, 45.48877320093142, 44.86363832049421, 44.24360112626026, 43.47982551751521, 42.85618414967468, 42.25820899404058, 41.64635601834687, 41.03621415169823, 40.429221007205776, 39.82920665196552, 39.26279703415516, 38.669230737912336, 38.07622553264989]\n"
     ]
    }
   ],
   "source": [
    "pso_best_loglikelihood, best_loglikelihood_init, large_gmm_init_score, particle_trajectories, g_best_reinit, basic_score = run_experiment_delta_parametrize(data_bc, log_file_name, n_components=10, amplitude=ampl, rank=rank, init_scale=init_scale)\n",
    "print(pso_best_loglikelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Big EM reinit 74.46991773731926\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_runs = 5\n",
    "scores = []\n",
    "for n in range(n_runs):\n",
    "    gmm_bc = GaussianMixture(n_components=10, init_params='random', covariance_type='full', n_init=600)\n",
    "    gmm_bc = gmm_bc.fit(data_bc)\n",
    "    scores.append(gmm_bc.score(data_bc))\n",
    "\n",
    "print(f'Big EM reinit {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scattered reinit 75.7775823597028 +- 0.5485572037925159\n",
      "Best EM init 73.9567769159048 +- 0.34635314330498546\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rank = 10\n",
    "n_runs = 5\n",
    "# more init scale\n",
    "init_scale = 0.003\n",
    "n_component = 10\n",
    "\n",
    "ampl = 0.003\n",
    "\n",
    "g_best_reinit_list = []\n",
    "basic_score_list = []\n",
    "for n in range(n_runs):\n",
    "    log_file_name = f'breast_cancer_pso_low_rank_parametrize_init_scale_{init_scale}_n_comp_{n_component}_ampl_{ampl}_rank_{rank}.log'\n",
    "    pso_best_loglikelihood, best_loglikelihood_init, large_gmm_init_score, particle_trajectories, g_best_reinit, basic_score = run_experiment_delta_parametrize(data_bc, log_file_name, n_components=n_component, amplitude=ampl, rank=rank, init_scale=init_scale)\n",
    "    g_best_reinit_list.append(g_best_reinit)\n",
    "    basic_score_list.append(basic_score)\n",
    "    final_score = pso_best_loglikelihood[-1]\n",
    "\n",
    "print('Best scattered reinit', np.mean(g_best_reinit_list), '+-' , np.std(g_best_reinit_list))\n",
    "print('Best EM init', np.mean(basic_score_list), '+-' , np.std(basic_score_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73.30267270173618"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_bc.score(data_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\pso\\PSO_GMM\\gmm_pso_low_rank_add.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X24sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mrun\u001b[39m\u001b[39m'\u001b[39m, n)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m log_file_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpso_low_rank_parametrize_init_scale_\u001b[39m\u001b[39m{\u001b[39;00minit_scale\u001b[39m}\u001b[39;00m\u001b[39m_n_comp_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m10\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m_ampl_\u001b[39m\u001b[39m{\u001b[39;00mampl\u001b[39m}\u001b[39;00m\u001b[39m_rank_\u001b[39m\u001b[39m{\u001b[39;00mrank\u001b[39m}\u001b[39;00m\u001b[39m.log\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X24sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m pso_best_loglikelihood, best_loglikelihood_init, large_gmm_init_score, particle_trajectories \u001b[39m=\u001b[39m run_experiment_delta_parametrize(cloud_data, log_file_name, n_components\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, amplitude\u001b[39m=\u001b[39;49mampl, rank\u001b[39m=\u001b[39;49mrank, init_scale\u001b[39m=\u001b[39;49minit_scale)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m final_score\u001b[39m.\u001b[39mappend(pso_best_loglikelihood[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n",
      "\u001b[1;32md:\\Projects\\pso\\PSO_GMM\\gmm_pso_low_rank_add.ipynb Cell 21\u001b[0m in \u001b[0;36mrun_experiment_delta_parametrize\u001b[1;34m(data, log_file_name, n_components, amplitude, rank, init_scale)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X24sZmlsZQ%3D%3D?line=137'>138</a>\u001b[0m criterions[i] \u001b[39m=\u001b[39m log_likelihood_gmm_parametrized(weights[i], delta_means[i], delta_diag_prec[i], delta_param_prec[i])\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X24sZmlsZQ%3D%3D?line=138'>139</a>\u001b[0m particle_trajectories[i]\u001b[39m.\u001b[39mappend(criterions[i])\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X24sZmlsZQ%3D%3D?line=139'>140</a>\u001b[0m \u001b[39mif\u001b[39;00m log_likelihood_gmm_parametrized(p_weights[i], p_delta_means[i], p_delta_diag_prec[i], p_delta_param_prec[i]) \u001b[39m<\u001b[39m criterions[i]:\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X24sZmlsZQ%3D%3D?line=140'>141</a>\u001b[0m     p_weights[i] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(weights[i])\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X24sZmlsZQ%3D%3D?line=141'>142</a>\u001b[0m     p_delta_means[i] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(delta_means[i])\n",
      "\u001b[1;32md:\\Projects\\pso\\PSO_GMM\\gmm_pso_low_rank_add.ipynb Cell 21\u001b[0m in \u001b[0;36mrun_experiment_delta_parametrize.<locals>.log_likelihood_gmm_parametrized\u001b[1;34m(weights, delta_means, delta_diag, delta_rank_params)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X24sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m gmm_init\u001b[39m.\u001b[39mmeans_ \u001b[39m=\u001b[39m means\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X24sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m gmm_init\u001b[39m.\u001b[39mprecisions_cholesky_ \u001b[39m=\u001b[39m cholesky\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Projects/pso/PSO_GMM/gmm_pso_low_rank_add.ipynb#X24sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m \u001b[39mreturn\u001b[39;00m gmm_init\u001b[39m.\u001b[39;49mscore(data)\n",
      "File \u001b[1;32mc:\\Users\\kholk\\Envs\\ml_base\\lib\\site-packages\\sklearn\\mixture\\_base.py:382\u001b[0m, in \u001b[0;36mBaseMixture.score\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscore\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    366\u001b[0m     \u001b[39m\"\"\"Compute the per-sample average log-likelihood of the given data X.\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \n\u001b[0;32m    368\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[39m        Log-likelihood of `X` under the Gaussian mixture model.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 382\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscore_samples(X)\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[1;32mc:\\Users\\kholk\\Envs\\ml_base\\lib\\site-packages\\sklearn\\mixture\\_base.py:363\u001b[0m, in \u001b[0;36mBaseMixture.score_samples\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    360\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    361\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_data(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 363\u001b[0m \u001b[39mreturn\u001b[39;00m logsumexp(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_estimate_weighted_log_prob(X), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\kholk\\Envs\\ml_base\\lib\\site-packages\\scipy\\special\\_logsumexp.py:99\u001b[0m, in \u001b[0;36mlogsumexp\u001b[1;34m(a, axis, b, keepdims, return_sign)\u001b[0m\n\u001b[0;32m     96\u001b[0m         a \u001b[39m=\u001b[39m a \u001b[39m+\u001b[39m \u001b[39m0.\u001b[39m  \u001b[39m# promote to at least float\u001b[39;00m\n\u001b[0;32m     97\u001b[0m         a[b \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf\n\u001b[1;32m---> 99\u001b[0m a_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mamax(a, axis\u001b[39m=\u001b[39;49maxis, keepdims\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    101\u001b[0m \u001b[39mif\u001b[39;00m a_max\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    102\u001b[0m     a_max[\u001b[39m~\u001b[39mnp\u001b[39m.\u001b[39misfinite(a_max)] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mamax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\kholk\\Envs\\ml_base\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2791\u001b[0m, in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2675\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_amax_dispatcher)\n\u001b[0;32m   2676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mamax\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[0;32m   2677\u001b[0m          where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[0;32m   2678\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2679\u001b[0m \u001b[39m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[0;32m   2680\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2789\u001b[0m \u001b[39m    5\u001b[39;00m\n\u001b[0;32m   2790\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2791\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mmaximum, \u001b[39m'\u001b[39;49m\u001b[39mmax\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, \u001b[39mNone\u001b[39;49;00m, out,\n\u001b[0;32m   2792\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[1;32mc:\\Users\\kholk\\Envs\\ml_base\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# recipe for experiments: EM inti iter =100, high ampl (lr), 100 pso iters, compare with EM init 200 iter\n",
    "# note: low lr for big number of components, try rank = 3, 5, 7\n",
    "# Add best EM init with zero addition\n",
    "# add an csv logging\n",
    "# fix a bug with global best\n",
    "\n",
    "rank = 3\n",
    "n_runs = 5\n",
    "init_scale = 0.003\n",
    "n_comp = 10\n",
    "ampl = 0.1\n",
    "final_score = []\n",
    "\n",
    "for n in range(n_runs):\n",
    "    print('run', n)\n",
    "    log_file_name = f'pso_low_rank_parametrize_init_scale_{init_scale}_n_comp_{10}_ampl_{ampl}_rank_{rank}.log'\n",
    "    pso_best_loglikelihood, best_loglikelihood_init, large_gmm_init_score, particle_trajectories = run_experiment_delta_parametrize(cloud_data, log_file_name, n_components=10, amplitude=ampl, rank=rank, init_scale=init_scale)\n",
    "    final_score.append(pso_best_loglikelihood[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LandSat Satelite experimnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6435, 36)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81538462, 0.8       , 0.77011494, 0.50413223, 0.69230769,\n",
       "       0.68181818, 0.58947368, 0.390625  , 0.6875    , 0.72815534,\n",
       "       0.54736842, 0.421875  , 0.95384615, 0.9       , 0.87368421,\n",
       "       0.592     , 0.8125    , 0.82524272, 0.71578947, 0.4375    ,\n",
       "       0.69230769, 0.73786408, 0.56842105, 0.40625   , 0.96923077,\n",
       "       0.95192308, 0.93333333, 0.6       , 0.75384615, 0.91262136,\n",
       "       0.82105263, 0.5546875 , 0.69230769, 0.77669903, 0.66315789,\n",
       "       0.453125  ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sat[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kholk\\envs\\ml_base\\lib\\site-packages\\sklearn\\mixture\\_base.py:286: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_components = [10, 25, 50]\n",
    "scores = []\n",
    "for n in n_components:\n",
    "    gmm_landsat = GaussianMixture(n_components=n, init_params='random', covariance_type='full')\n",
    "    gmm_landsat = gmm_landsat.fit(data_sat)\n",
    "    scores.append(gmm_landsat.score(data_sat))\n",
    "\n",
    "plt.plot(n_components, scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_scale_range = [0.01, 0.0005]\n",
    "n_comp = [10]\n",
    "ampl_list = [0.1]\n",
    "\n",
    "# recipe for experiments: EM inti iter =100, high ampl (lr), 100 pso iters, compare with EM init 200 iter\n",
    "# note: low lr for big number of components, try rank = 3, 5, 7\n",
    "# Add best EM init with zero addition\n",
    "# add an csv logging\n",
    "# fix a bug with global best\n",
    "rank = 5\n",
    "n_runs = 5\n",
    "init_scale = 0.01\n",
    "init_scale = 0.05\n",
    "\n",
    "ampl = 0.1\n",
    "\n",
    "g_best_reinit_list = []\n",
    "basic_score_list = []\n",
    "for n in range(n_runs):\n",
    "    log_file_name = f'landsat_low_rank_parametrize_init_scale_{init_scale}_n_comp_{10}_ampl_{ampl}_rank_{rank}.log'\n",
    "    pso_best_loglikelihood, best_loglikelihood_init, large_gmm_init_score, particle_trajectories, g_best_reinit, basic_score = run_experiment_delta_parametrize(cloud_data, log_file_name, n_components=10, amplitude=ampl, rank=rank, init_scale=init_scale)\n",
    "    g_best_reinit_list.append(g_best_reinit)\n",
    "    basic_score_list.append(basic_score)\n",
    "    final_score = pso_best_loglikelihood[-1]\n",
    "\n",
    "print('Best scattered reinit', np.mean(g_best_reinit_list), '+-' , np.std(g_best_reinit_list))\n",
    "print('Best EM init', np.mean(basic_score_list), '+-' , np.std(basic_score_list))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('ml_base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9bfb2d55de37064be05f21953ecbbe4c1eff451757a1067937cd706768d7c377"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
